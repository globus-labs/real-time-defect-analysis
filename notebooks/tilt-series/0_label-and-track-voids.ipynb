{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f5a6a9-42c8-4547-91f3-7484f6d5d5df",
   "metadata": {},
   "source": [
    "# Label and Track Voids\n",
    "Our first step in gathering the 3D positions of voids is to identify their location in each image of the tilt series, then track their movement across each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18dadee0-a95b-4190-a2ea-578412ba96e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lward/miniconda3/envs/rtdefects/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from rtdefects.drift import compute_drift_from_images\n",
    "from rtdefects.segmentation.pytorch import PyTorchSemanticSegmenter\n",
    "from rtdefects.analysis import analyze_defects, convert_to_per_particle, compile_void_tracks\n",
    "from rtdefects.io import load_file\n",
    "from collections import defaultdict\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import trackpy as tp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3ff7a-2eb2-4a8f-87ca-df84f573c476",
   "metadata": {},
   "source": [
    "TODO: Convert from pixels to nm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab829c16-fc1c-449c-a9b2-922fac74c4c9",
   "metadata": {},
   "source": [
    "## Load the Images\n",
    "Get the names of positions of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d3e29c-3d45-4bad-b0fb-5adf75931e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 from tilt series\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for image in Path('images/').glob('tilt*.png'):\n",
    "    images.append({\n",
    "        'path': str(image),\n",
    "        'frame': int(image.name[4:-4])\n",
    "    })\n",
    "images = pd.DataFrame(images).sort_values('frame')\n",
    "print(f'Loaded {len(images)} from tilt series')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbec934-0180-44d5-8f83-19504185a291",
   "metadata": {},
   "source": [
    "## Segment them\n",
    "Use the latest model from the void segmentation approach. The procedure for analyzing a single image is to:\n",
    "\n",
    "1. Load image from disk into a standard representation: grayscale represented as a floating point between 0-1\n",
    "2. Convert image into the form needed by a particular model\n",
    "3. Run segmentation to get the pixels for each void\n",
    "4. Run analysis to get a summary of the positions, sizes, etc for each void"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5768c4ae-cdf6-48ad-be5f-3ebaca291fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the small_voids_031023.pth segmentation model.\n"
     ]
    }
   ],
   "source": [
    "segmenter = PyTorchSemanticSegmenter()\n",
    "print(f'Loaded the {segmenter.model_path.name} segmentation model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a20542-619b-49bf-a957-ae60bd4ea79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:34<00:00,  3.41s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for path in tqdm(images['path']):\n",
    "    img = load_file(path)\n",
    "    std_img = segmenter.transform_standard_image(img)\n",
    "    labeled_img = segmenter.perform_segmentation(std_img)\n",
    "    result = analyze_defects(labeled_img)\n",
    "    result['labeled_img'] = labeled_img\n",
    "    results.append(result)\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09398a62-c146-45be-b418-09da24c68bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.concat([images, results], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52d51c-2b06-49df-8c59-4a4c1466b3b5",
   "metadata": {},
   "source": [
    "We now have the locations and sizes of voids for each frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ebd63-e677-41c5-a81a-9c0ef3277ade",
   "metadata": {},
   "source": [
    "## Use FFT-based Drift Correction\n",
    "The drift between frames in a tilt series is large and FFTs provide a robust way to determine a drift between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459715ba-ecd5-461a-9163-a0908a131b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labeled_image_to_mask(labeled_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convert a labeled image to a 2D boolean array\n",
    "\n",
    "    Args:\n",
    "        labeled_img: Image to be converted\n",
    "    Returns:\n",
    "        A simple mask\n",
    "    \"\"\"\n",
    "    return labeled_img.any(axis=0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643b09c-7974-410a-adae-8d323a0c8451",
   "metadata": {},
   "source": [
    "Get the drift between all pairs of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4ebb0f-380b-4ef6-bf67-3450025a6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pairs = (len(results) - 1) * len(results) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8371a5f8-444c-4fd0-b303-ad9a55d955ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "drifts_in = np.zeros((n_pairs, len(results)))\n",
    "drifts_out = np.zeros((n_pairs, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82cb55e6-636e-4360-8323-0086b4c14509",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0\n",
    "for i in range(len(results)):\n",
    "    image_i = convert_labeled_image_to_mask(results['labeled_img'].iloc[i])\n",
    "    for j in range(i):\n",
    "        image_j = convert_labeled_image_to_mask(results['labeled_img'].iloc[j])\n",
    "        drift = compute_drift_from_images(image_i, image_j)\n",
    "        drifts_in[pos, i] = 1\n",
    "        drifts_in[pos, j] = -1\n",
    "        drifts_out[pos, :] = drift\n",
    "        pos += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363a5bb-950d-4b1b-8a03-fe2f01f2f754",
   "metadata": {},
   "source": [
    "Estimate the drift using least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24608b9f-0bfb-46d8-98aa-ab6f620ae739",
   "metadata": {},
   "outputs": [],
   "source": [
    "drifts, _, _, _ = np.linalg.lstsq(drifts_in, drifts_out, rcond=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6de8d-522f-4f6d-8275-ed12ee92fa10",
   "metadata": {},
   "source": [
    "Plot them in a progressive series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70f877-67dd-4bb4-b59d-7a0d69ba51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 3.5))\n",
    "\n",
    "for frame, drift in zip(results['labeled_img'], drifts):\n",
    "    # Make mask then adjust with the drift\n",
    "    mask = convert_labeled_image_to_mask(frame)\n",
    "    mask_shifted = warp(mask, AffineTransform(translation=drift))\n",
    "\n",
    "    # Make a image read\n",
    "    image = np.zeros((*mask.shape, 3), dtype=np.uint8) + 255\n",
    "    image[:, :, :2] -= np.array(mask_shifted * 255, dtype=np.uint8)[:, :, None]\n",
    "\n",
    "    ax.imshow(image, cmap='Blues', alpha=0.4)\n",
    "ax.set_yticks(ax.set_xticks([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1fb80-e122-4f0e-948c-e6e5e76462c4",
   "metadata": {},
   "source": [
    "Adjust the positions using the computed drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cceb0b-91cc-4672-8035-9ee8208117be",
   "metadata": {},
   "outputs": [],
   "source": [
    "images['positions-no-drift'] = images.apply(lambda x: np.subtract(x['positions'], drifts[x['frame'] - 1, :]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843a673-f584-45c0-8462-ec4d9efd332e",
   "metadata": {},
   "source": [
    "## Run the Particle Tracking\n",
    "We use [trackpy](https://soft-matter.github.io/trackpy/dev/), which expects each row in the dataframe to be a particle rather than a frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89595180-92b0-4bdb-ade7-bf4dc1e8b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = pd.concat(list(convert_to_per_particle(images, position_col='positions-no-drift'))).query('not touches_side')\n",
    "particles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45018dae-1feb-4dc1-9c71-c33a50c6738d",
   "metadata": {},
   "source": [
    "Run the tracking, using a wide search range for the drift of a single void and no memory for voids being lost between frames.\n",
    "\n",
    "Rationale: We are only looking for a few easy-to-track particles to use when determining the tilt axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2058f-78d4-49d8-84ce-86fe5ad351ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tp.link_df(particles, search_range=20, memory=2)\n",
    "print(f'Found a total of {len(tracks.particle.value_counts())} unique particles out of {len(particles)} labelled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc7aea-b01a-4b6d-a99f-84b5cb656651",
   "metadata": {},
   "source": [
    "The output is the void in each frame assigned with a global ID, \"particle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b09fa8-da58-40af-8249-8454c65ccf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b18ad0-a7f3-4d85-bd7c-2d65d7e34d56",
   "metadata": {},
   "source": [
    "We'll next produce a summary where we group the same particule into each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b004dc4-9939-4492-8359-9d997b4a2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "void_tracks = compile_void_tracks(tracks)\n",
    "void_tracks.sort_values('total_frames', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a447f-5c7a-4017-ad48-65e84c684aeb",
   "metadata": {},
   "source": [
    "Plot the tracks for the voids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac312e5f-f53d-4f91-a206-96cd7ef982ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "\n",
    "ax.set_yticks(ax.set_xticks([]))\n",
    "for p in void_tracks.query('total_frames > 6')['positions']: \n",
    "    ax.plot(p[:, 0], p[:, 1])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078d508-b5e1-4f5d-8ee9-38543411215d",
   "metadata": {},
   "source": [
    "## Save for later use\n",
    "Let's save a few things separately.\n",
    "\n",
    "First, the data for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b1bc7-713d-41e8-87ac-9bd2c4420ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(columns=['labeled_img']).to_json('frame-data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf97c7-9467-4ed3-a03b-07ebd92483b1",
   "metadata": {},
   "source": [
    "Then the summary of void tracks, in full detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5129a-f7e5-4e54-9d83-04c66b4226cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "void_tracks.to_json('track-data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95947a8-8152-4fe4-aa83-9dfb19d1a840",
   "metadata": {},
   "source": [
    "Now the CSV of voids that are tracked across many frames coordinates in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2511cf-38cb-4ecb-8944-136019998f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked_coords = defaultdict(list)\n",
    "for rid, row in void_tracks.query('total_frames >= 8').iterrows():\n",
    "    for i, (x, y) in enumerate(row['positions']):\n",
    "        tracked_coords['id'].append(rid)\n",
    "        tracked_coords['frame'].append(i + row['start_frame'])\n",
    "        tracked_coords['x'].append(x)\n",
    "        tracked_coords['y'].append(y)\n",
    "    tracked_coords['r'].extend(row['radii'])\n",
    "tracked_coords = pd.DataFrame(tracked_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15579dbf-c26d-43f8-a7ab-2afdd49a400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked_coords.to_csv('void-2d-coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e6cfd-341b-4c62-88ae-3a623ca47efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
