"""Algorithms for correcting drift in microscopy images"""
from typing import Iterable

import numpy as np
import pandas as pd
from scipy.signal import fftconvolve
from skimage.transform import AffineTransform, warp


def compute_drifts_from_tracks(tracks: pd.DataFrame, minimum_tracks: int = 1) -> np.ndarray:
    """Estimate the drift for each frame from the positions of voids that were mapped between multiple frames

    We determine the "drift" based on the median displacement of all voids, which is based
    on the assumption that there is no net motion of all the voids.

    We compute the drift in each frame and assume the drift remains unchanged if there are no voids matched
    between a frame and the previous.

    In contrast, trackpy uses the mean and only computes drift when there are matches between frames.

    Args:
        tracks: Track information generated by trackpy.
        minimum_tracks: The minimum number of tracks a void must appear to be used in drift correction
    Returns:
        Drift correction for each frame
    """

    # We'll assume that the first frame has a void
    drifts = [(0, 0)]

    # We're going to go frame-by-frame and guess the drift from the previous frame
    last_frame = tracks.query('frame==0')
    for fid in range(1, tracks['frame'].max() + 1):
        # Join the two frames
        my_frame = tracks.query(f'frame=={fid}')
        aligned = last_frame.merge(my_frame, on='particle')

        # The current frame will be the previous for the next iteration
        last_frame = my_frame

        # If there are no voids in both frames, assign a drift change of 0
        if len(aligned) < minimum_tracks:
            drifts.append(drifts[-1])
            continue

        # Get the median displacements displacements
        last_pos = aligned[['x_x', 'y_x']].values
        cur_pos = aligned[['x_y', 'y_y']].values
        median_disp = np.mean(cur_pos - last_pos, axis=0)

        # Add the drift to that of the previous image
        drift = np.add(drifts[-1], median_disp)
        drifts.append(drift)

    return np.array(drifts)


def compute_drifts_from_images(images: list[np.ndarray], return_conv: bool = False) -> np.ndarray | tuple[np.ndarray, np.ndarray]:
    """Estimate drift from a stack of images

    Compares adjacent pairs of images in the list

    Args:
        images: Images arranged sequentially
        return_conv: Whether to return the convolution between each pair of images
    """

    # Get the drift between adjacent pairs
    convs = []
    drifts = []
    for image_1, image_2 in zip(images, images[1:]):
        drift, conv = compute_drift_from_image_pair(image_1, image_2, return_conv=True)
        drifts.append(drift)
        convs.append(conv)

    # Get the cumulative drift
    drifts = np.cumsum(drifts, axis=0)
    if return_conv:
        return drifts, np.array(convs)
    return drifts


def compute_drifts_from_images_multiref(images: list[np.ndarray], lookahead: Iterable[int] = (1, 2, 4)):
    """Estimate drift for a stack of images by comparing each image to multiple images in the stack

    Estimates a single drift for each image which explains all pairwise comparisons
    made between images in the stack using linear least squares.

    The relative drift between two pairs of images, :math:`\\delta d_{i,j}`, is equal to the
    difference between their absolute drifts, :math:`\\delta d_{i,j} = d_j - d_i`.
    The values of relative drift from observations of :math:`\\delta_{i,j}`
    form a series of linear equations and thus may be solved using linear least squares.

    Args:
          images: Images arranged
          lookahead: Compute the drift between each frame and those these number of steps
            ahead of it in the sequence
    Returns:
        Drift assumed from all comparisons
    """

    # Compute the drift between all pairs
    lookahead = list(lookahead)
    if any(i <= 0 for i in lookahead):
        raise ValueError('All lookahead values must be positive')
    pair_drifts = []
    first = []
    second = []
    for step in lookahead:
        for i, (image_1, image_2) in enumerate(zip(images, images[step:])):
            pair_drifts.append(compute_drift_from_image_pair(image_1, image_2))
            first.append(i)
            second.append(i + step)

    # Solve the least squares problem
    a = np.zeros((len(pair_drifts), len(images)))
    i = np.arange(len(pair_drifts))
    a[i, first] = -1
    a[i, second] = 1
    return np.linalg.lstsq(a, pair_drifts, rcond=None)[0]


def compute_drift_from_image_pair(image_1: np.ndarray, image_2: np.ndarray, return_conv: bool = False) -> np.ndarray | tuple[np.ndarray, np.ndarray]:
    """Compute the drift between two different frames

    Args:
        image_1: Starting image
        image_2: Next image
        return_conv: Whether to return the convolution between the two images
    Returns:
        - The optimal translation between the two images
        - Convolution used to make the judgement, if ``return_conv`` is True
    """

    # Compute the correlations between the two images using FFT
    #  You must reverse the second signal/image for this trick
    conv = fftconvolve(image_1, image_2[::-1, ::-1], mode='same')

    # Find the location of the maximum
    peak_loc = np.unravel_index(np.argmax(conv), conv.shape)

    # Find its displacement from the image center, that's the location
    drift = [peak_loc[1] - conv.shape[0] // 2, peak_loc[0] - conv.shape[1] // 2]
    if return_conv:
        return -np.array(drift), conv
    return -np.array(drift)


def subtract_drift_from_images(images: list[np.ndarray], drifts: np.ndarray) -> list[np.ndarray]:
    """Subtract the drift from each image in a series

    Args:
        images: List of images
        drifts: Drift computed for the images in the stack
    Returns:
        List of images after correction
    """

    return [warp(image, AffineTransform(translation=-drift)) for image, drift in zip(images, drifts)]
